

















name: ðŸŽ¾ Tennis Coach Platform - Automated Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - api
          - frontend
          - integration
          - accessibility
          - performance
      environment:
        description: 'Environment to test against'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

env:
  NODE_VERSION: '18'
  PLAYWRIGHT_VERSION: '1.40.0'

jobs:
  setup:
    name: ðŸ”§ Setup and Validation
    runs-on: ubuntu-latest
    outputs:
      base-url: ${{ steps.get-url.outputs.base-url }}
      test-suite: ${{ steps.config.outputs.test-suite }}
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ” Determine test configuration
        id: config
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "test-suite=${{ github.event.inputs.test_suite }}" >> $GITHUB_OUTPUT
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          else
            echo "test-suite=all" >> $GITHUB_OUTPUT
            echo "environment=production" >> $GITHUB_OUTPUT
          fi
      
      - name: ðŸŒ Get deployment URL
        id: get-url
        run: |
          # In a real scenario, you would get this from your deployment
          # For now, we'll use a placeholder that should be replaced
          if [ "${{ steps.config.outputs.environment }}" = "production" ]; then
            echo "base-url=${{ secrets.PRODUCTION_BASE_URL }}" >> $GITHUB_OUTPUT
          elif [ "${{ steps.config.outputs.environment }}" = "staging" ]; then
            echo "base-url=${{ secrets.STAGING_BASE_URL }}" >> $GITHUB_OUTPUT
          else
            echo "base-url=${{ secrets.DEVELOPMENT_BASE_URL }}" >> $GITHUB_OUTPUT
          fi
      
      - name: âœ… Validate configuration
        run: |
          echo "Test Suite: ${{ steps.config.outputs.test-suite }}"
          echo "Environment: ${{ steps.config.outputs.environment }}"
          echo "Base URL: ${{ steps.get-url.outputs.base-url }}"

  api-tests:
    name: ðŸ”Œ API Layer Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-suite == 'all' || needs.setup.outputs.test-suite == 'api'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json
      
      - name: ðŸ“¦ Install dependencies
        working-directory: tests
        run: |
          npm ci
          npx playwright install chromium
      
      - name: ðŸ”§ Configure environment
        working-directory: tests
        run: |
          echo "BASE_URL=${{ needs.setup.outputs.base-url }}" > .env
          echo "CI=true" >> .env
          echo "TEST_TIMEOUT=60000" >> .env
      
      - name: ðŸ§ª Run API tests
        working-directory: tests
        run: npx playwright test e2e/api.spec.ts --reporter=html,json,junit
      
      - name: ðŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: api-test-results
          path: |
            tests/test-results/
            tests/playwright-report/
          retention-days: 7

  frontend-tests:
    name: ðŸŽ¨ Frontend UI Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-suite == 'all' || needs.setup.outputs.test-suite == 'frontend'
    
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json
      
      - name: ðŸ“¦ Install dependencies
        working-directory: tests
        run: |
          npm ci
          npx playwright install ${{ matrix.browser }}
      
      - name: ðŸ”§ Configure environment
        working-directory: tests
        run: |
          echo "BASE_URL=${{ needs.setup.outputs.base-url }}" > .env
          echo "CI=true" >> .env
          echo "BROWSER=${{ matrix.browser }}" >> .env
      
      - name: ðŸ§ª Run frontend tests
        working-directory: tests
        run: npx playwright test e2e/frontend.spec.ts --project=${{ matrix.browser }} --reporter=html,json
      
      - name: ðŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-test-results-${{ matrix.browser }}
          path: |
            tests/test-results/
            tests/playwright-report/
          retention-days: 7

  integration-tests:
    name: ðŸ”— Integration Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-suite == 'all' || needs.setup.outputs.test-suite == 'integration'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json
      
      - name: ðŸ“¦ Install dependencies
        working-directory: tests
        run: |
          npm ci
          npx playwright install
      
      - name: ðŸ”§ Configure environment
        working-directory: tests
        run: |
          echo "BASE_URL=${{ needs.setup.outputs.base-url }}" > .env
          echo "CI=true" >> .env
          echo "RUN_INTEGRATION_TESTS=true" >> .env
      
      - name: ðŸ§ª Run integration tests
        working-directory: tests
        run: npx playwright test e2e/integration.spec.ts --reporter=html,json
      
      - name: ðŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            tests/test-results/
            tests/playwright-report/
          retention-days: 7

  accessibility-tests:
    name: â™¿ Accessibility Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-suite == 'all' || needs.setup.outputs.test-suite == 'accessibility'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json
      
      - name: ðŸ“¦ Install dependencies
        working-directory: tests
        run: |
          npm ci
          npx playwright install chromium
      
      - name: ðŸ”§ Configure environment
        working-directory: tests
        run: |
          echo "BASE_URL=${{ needs.setup.outputs.base-url }}" > .env
          echo "CI=true" >> .env
          echo "RUN_ACCESSIBILITY_TESTS=true" >> .env
          echo "WCAG_LEVEL=AA" >> .env
      
      - name: ðŸ§ª Run accessibility tests
        working-directory: tests
        run: npx playwright test e2e/accessibility.spec.ts --reporter=html,json
      
      - name: ðŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-test-results
          path: |
            tests/test-results/
            tests/playwright-report/
          retention-days: 7

  performance-tests:
    name: âš¡ Performance Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-suite == 'all' || needs.setup.outputs.test-suite == 'performance'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json
      
      - name: ðŸ“¦ Install dependencies
        working-directory: tests
        run: |
          npm ci
          npx playwright install chromium
      
      - name: ðŸ”§ Configure environment
        working-directory: tests
        run: |
          echo "BASE_URL=${{ needs.setup.outputs.base-url }}" > .env
          echo "CI=true" >> .env
          echo "RUN_PERFORMANCE_TESTS=true" >> .env
          echo "MAX_PAGE_LOAD_TIME=5000" >> .env
          echo "MAX_API_RESPONSE_TIME=3000" >> .env
      
      - name: ðŸ§ª Run performance tests
        working-directory: tests
        run: npx playwright test e2e/performance.spec.ts --reporter=html,json
      
      - name: ðŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: |
            tests/test-results/
            tests/playwright-report/
          retention-days: 7

  test-report:
    name: ðŸ“‹ Generate Test Report
    runs-on: ubuntu-latest
    needs: [api-tests, frontend-tests, integration-tests, accessibility-tests, performance-tests]
    if: always()
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ“¥ Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts
      
      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: ðŸ“Š Combine test results
        run: |
          mkdir -p combined-results
          find test-artifacts -name "*.json" -exec cp {} combined-results/ \;
          find test-artifacts -name "*.xml" -exec cp {} combined-results/ \;
      
      - name: ðŸ“ˆ Generate summary report
        run: |
          echo "# ðŸŽ¾ Tennis Coach Platform - Test Results Summary" > test-summary.md
          echo "" >> test-summary.md
          echo "**Test Run:** $(date)" >> test-summary.md
          echo "**Commit:** ${{ github.sha }}" >> test-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> test-summary.md
          echo "" >> test-summary.md
          
          # Add test status for each job
          echo "## Test Results by Suite" >> test-summary.md
          echo "" >> test-summary.md
          
          if [ "${{ needs.api-tests.result }}" = "success" ]; then
            echo "- âœ… **API Tests:** Passed" >> test-summary.md
          elif [ "${{ needs.api-tests.result }}" = "failure" ]; then
            echo "- âŒ **API Tests:** Failed" >> test-summary.md
          else
            echo "- â­ï¸ **API Tests:** Skipped" >> test-summary.md
          fi
          
          if [ "${{ needs.frontend-tests.result }}" = "success" ]; then
            echo "- âœ… **Frontend Tests:** Passed" >> test-summary.md
          elif [ "${{ needs.frontend-tests.result }}" = "failure" ]; then
            echo "- âŒ **Frontend Tests:** Failed" >> test-summary.md
          else
            echo "- â­ï¸ **Frontend Tests:** Skipped" >> test-summary.md
          fi
          
          if [ "${{ needs.integration-tests.result }}" = "success" ]; then
            echo "- âœ… **Integration Tests:** Passed" >> test-summary.md
          elif [ "${{ needs.integration-tests.result }}" = "failure" ]; then
            echo "- âŒ **Integration Tests:** Failed" >> test-summary.md
          else
            echo "- â­ï¸ **Integration Tests:** Skipped" >> test-summary.md
          fi
          
          if [ "${{ needs.accessibility-tests.result }}" = "success" ]; then
            echo "- âœ… **Accessibility Tests:** Passed" >> test-summary.md
          elif [ "${{ needs.accessibility-tests.result }}" = "failure" ]; then
            echo "- âŒ **Accessibility Tests:** Failed" >> test-summary.md
          else
            echo "- â­ï¸ **Accessibility Tests:** Skipped" >> test-summary.md
          fi
          
          if [ "${{ needs.performance-tests.result }}" = "success" ]; then
            echo "- âœ… **Performance Tests:** Passed" >> test-summary.md
          elif [ "${{ needs.performance-tests.result }}" = "failure" ]; then
            echo "- âŒ **Performance Tests:** Failed" >> test-summary.md
          else
            echo "- â­ï¸ **Performance Tests:** Skipped" >> test-summary.md
          fi
          
          echo "" >> test-summary.md
          echo "## ðŸ“Š Detailed Reports" >> test-summary.md
          echo "" >> test-summary.md
          echo "Detailed test reports and artifacts are available in the workflow artifacts." >> test-summary.md
      
      - name: ðŸ“¤ Upload combined results
        uses: actions/upload-artifact@v4
        with:
          name: combined-test-results
          path: |
            combined-results/
            test-summary.md
          retention-days: 30
      
      - name: ðŸ’¬ Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

















